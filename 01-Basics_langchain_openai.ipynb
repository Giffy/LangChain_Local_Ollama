{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb92356d",
   "metadata": {},
   "source": [
    "To run this notebook is it required an Api Key from OpenAI get one in https_//platform.openai.com/api-keys.\n",
    "\n",
    "The model used is:\n",
    "- gpt-5-nano\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199bdff2",
   "metadata": {},
   "source": [
    "### Tutorial LangChain but updated to use OpenAI from https://docs.langchain.com/oss/python/langchain/quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13dbac1",
   "metadata": {},
   "source": [
    "### Test OpenAI connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dedf5fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They imitate sounds they've heard.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "MODEL='gpt-5-nano'\n",
    "\n",
    "load_dotenv()  # Loads .env variables as environment variables\n",
    "\n",
    "model = init_chat_model(MODEL)\n",
    "response = model.invoke(\"Why do parrots talk? in 5 words\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12304636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|To| attract| mates| and| communicate|.||||"
     ]
    }
   ],
   "source": [
    "# Basic streaming response\n",
    "for chunk in model.stream(\"Why do parrots have colorful feathers? in 5 words\"):\n",
    "    print(chunk.text, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e744b59e",
   "metadata": {},
   "source": [
    "### Build a basic agent OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e565b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is the weather in sf', additional_kwargs={}, response_metadata={}, id='d31705fa-5fe4-4f80-968c-ca606b8b7254'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 216, 'prompt_tokens': 140, 'total_tokens': 356, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CmogHBrHIIVhuCIGcxbD9biRuE8ek', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b1eef-e666-7950-be88-bf81cad67229-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': 'call_wOlJzsg9qYKWbgZ4KQ0XTQ2X', 'type': 'tool_call'}], usage_metadata={'input_tokens': 140, 'output_tokens': 216, 'total_tokens': 356, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}}),\n",
       "  ToolMessage(content=\"It's always sunny in San Francisco!\", name='get_weather', id='b8b68fbf-8555-4af3-836d-03514e1a4178', tool_call_id='call_wOlJzsg9qYKWbgZ4KQ0XTQ2X'),\n",
       "  AIMessage(content=\"Current weather in San Francisco: It's always sunny in San Francisco!\\n\\nWant more details like temperature, humidity, wind, or a short forecast? I can pull those up next.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 428, 'prompt_tokens': 176, 'total_tokens': 604, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 384, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CmogKVjPNdCr75tHKUSjySHP61ZpT', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b1eef-f132-7e70-9848-0e61b8ef993f-0', usage_metadata={'input_tokens': 176, 'output_tokens': 428, 'total_tokens': 604, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 384}})]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=MODEL,\n",
    "    tools=[get_weather],\n",
    "    system_prompt=\"You are a helpful assistant\",\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a363a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'validate_user', 'args': {'user_id': 123, 'addresses': ['123 Fake St in Boston MA', '234 Pretend Boulevard in Houston TX']}, 'id': 'call_FidRPhBMnDrmzJikMClzsfc8', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "# https://docs.langchain.com/oss/python/integrations/chat/ollama\n",
    "from typing import List\n",
    "\n",
    "from langchain.messages import AIMessage\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "@tool\n",
    "def validate_user(user_id: int, addresses: List[str]) -> bool:\n",
    "    \"\"\"Validate user using historical addresses.\n",
    "\n",
    "    Args:\n",
    "        user_id (int): the user ID.\n",
    "        addresses (List[str]): Previous addresses as a list of strings.\n",
    "    \"\"\"\n",
    "    return True\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=MODEL,\n",
    "                 temperature=0,\n",
    "                ).bind_tools([validate_user])\n",
    "\n",
    "messages = [(\"system\", \"you are a helpful assistant\"),\n",
    "            (\"human\", \"Could you validate user 123? They previously lived at 123 Fake St in Boston MA and 234 Pretend Boulevard in Houston TX.\"),\n",
    "]\n",
    "\n",
    "result = llm.invoke(messages)\n",
    "\n",
    "if isinstance(result, AIMessage) and result.tool_calls:\n",
    "    print(result.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78e85127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "\n",
      "(3 cubed = 3 × 3 × 3 = 27)\n"
     ]
    }
   ],
   "source": [
    "# Using a non reasoning model\n",
    "from langchain.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=MODEL)\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(\"What is 3^3?\"),\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91de8cc",
   "metadata": {},
   "source": [
    "### Build a real-world agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e3ecdd",
   "metadata": {},
   "source": [
    "This example is available in https://docs.langchain.com/oss/python/langchain/quickstart using Claude Sonnet 4.5.\n",
    "For this example I used OpenAI an local model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c39ed4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system prompt\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert weather forecaster, who speaks in puns.\n",
    "            You have access to two tools:\n",
    "            - get_weather_for_location: use this to get the weather for a specific location\n",
    "            - get_user_location: use this to get the user's location\n",
    "            If a user asks you for the weather, make sure you know the location. If you can tell \n",
    "            from the question that they mean wherever they are, use the get_user_location tool \n",
    "            to find their location.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebba566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tools\n",
    "from dataclasses import dataclass\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "@tool\n",
    "def get_weather_for_location(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    print(f'get_weather_argument : {city}')\n",
    "    if city == \"Florida\":\n",
    "        return f\"It's always sunny in {city}!\"\n",
    "    return f\"It's raining in {city}!\"\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    \"\"\"Custom runtime context schema.\"\"\"\n",
    "    user_id: str\n",
    "\n",
    "@tool\n",
    "def get_user_location(runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Retrieve user information based on user ID.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    print(f'get_user_location_argument : {user_id}')\n",
    "    return \"Florida\" if user_id == \"1\" else \"SF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "640628e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure your model\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model=init_chat_model(model=MODEL, \n",
    "                      temperature=0.5,\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4136c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add memory\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "checkpointer = InMemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1330ca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def responseFormat(response):\n",
    "    for item in response[\"messages\"]:\n",
    "        if isinstance(item, HumanMessage):\n",
    "            if item.content:\n",
    "                print(f\"Query : {item.content}\")\n",
    "        if isinstance(item, AIMessage):\n",
    "            if item.content:\n",
    "                print(f\"AI response: {item.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd678752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and run model\n",
    "from langchain.messages import AIMessage\n",
    "from langchain.messages import HumanMessage\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    tools=[get_user_location, get_weather_for_location],\n",
    "    context_schema=Context,\n",
    "    checkpointer=checkpointer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17004472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_user_location_argument : 1\n",
      "get_weather_argument : Florida\n",
      "Query : Tell me my location and what the weather outside is.\n",
      "AI response: Location: Florida\n",
      "Weather: It’s always sunny in Florida!\n",
      "\n",
      "Punny tip: Sun’s out, fun’s out—slap on some sunscreen and grab those shades before you soak up that radiant day.\n",
      "\n",
      "Want a city-specific or hourly forecast for where you are in Florida? I can drizzle you with more details.\n",
      "Query : thank you!\n",
      "AI response: You're welcome! Happy to keep the sunshine on your side. If you want more detail—city-level, hourly, rain chances, or UV index—just say the word and I’ll give you the full forecast. Until then, stay sunny and sunscreen-up!\n"
     ]
    }
   ],
   "source": [
    "# `thread_id` is a unique identifier for a given conversation.\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Tell me my location and what the weather outside is.\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "# # Note that we can continue the conversation using the same `thread_id`.\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"thank you!\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "responseFormat(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58f891a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_user_location_argument : 2\n",
      "get_weather_argument : San Francisco\n",
      "Query : Tell me my location and what the weather outside is.\n",
      "AI response: You're in San Francisco. Weather: It's raining in San Francisco.\n",
      "\n",
      "Tip: grab an umbrella or a rain jacket—the city by the bay is putting on a wet show. Stay dry out there!\n",
      "Query : thank you!\n",
      "AI response: You're welcome! If you want another forecast—or just a sunny pun—I'm here to weather the request. Have a great day!\n"
     ]
    }
   ],
   "source": [
    "# `thread_id` is a unique identifier for a given conversation.\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Tell me my location and what the weather outside is.\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"2\")\n",
    ")\n",
    "\n",
    "# # Note that we can continue the conversation using the same `thread_id`.\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"thank you!\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"2\")\n",
    ")\n",
    "\n",
    "responseFormat(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce0567d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-local-ollama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
